---
layout: post
title: Synthesizing Demographic Data
date: '2020-01-16T09:49:00.001+02:00'
author: Aleksi Sitomaniemi
tags:
- AI
- ML
- model interpretability
- GAN
- DataSynthesis
nav_order: 4
modified_time: '2020-02-03T08:46:08.153+02:00'
thumbnail: https://1.bp.blogspot.com/-zF5HyzdW-SU/Xhh-4rzpQ5I/AAAAAAAAAIc/cEQoHDwS77wvi_mTgJvjwd06Xb8PpechwCLcBGAsYHQ/s72-c/80633458_l.jpg
blogger_id: tag:blogger.com,1999:blog-3014413452006891711.post-6944846243479813028
blogger_orig_url: https://blog.boogiesoftware.com/2020/01/synthesizing-demographic-data.html
---

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-zF5HyzdW-SU/Xhh-4rzpQ5I/AAAAAAAAAIc/cEQoHDwS77wvi_mTgJvjwd06Xb8PpechwCLcBGAsYHQ/s1600/80633458_l.jpg" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" data-original-height="1600" data-original-width="1600" height="320" src="https://1.bp.blogspot.com/-zF5HyzdW-SU/Xhh-4rzpQ5I/AAAAAAAAAIc/cEQoHDwS77wvi_mTgJvjwd06Xb8PpechwCLcBGAsYHQ/s320/80633458_l.jpg" width="320" /></a></div>Synthetic data is data that resembles real data but is generated artificially. There are various methods to create synthetic data. The simplest way to generate data might be picking random values from a range or a list. More sophisticated methods include agent based solutions, bayesian sampling and neural networks. <br /><br />Synthetic data can be helpful in various test and development scenarios where real data is not available. Real data is often sensitive, and as such it cannot be used without access control and other precautions. In some situations real data may be too scarce for building a particular feature, even when there are no any privacy restrictions. <br /><br />In this article I present results of an experiment where I used our&nbsp;<b>Data Synthesizer Solution</b> on a demographic dataset to evaluate synthetic data applicability for machine learning. The data used is the <a href="https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29">Census Income (KDD) Dataset</a> from UCI Machine Learning Repository.<br /><br /><i>TLDR; Synthetic data can be used to develop machine learning models, with certain restrictions. See the <a href="https://blog.boogiesoftware.com/2020/01/synthesizing-demographic-data.html#Conclusions">Conclusions</a> chapter for a summary.</i><br /><br />More information about the Boogie Software Data Synthesizer solution available on our website at <a href="https://boogiesoftware.com/datasynth/">https://boogiesoftware.com/datasynth/</a>.<br /><h3>Dataset preparation</h3>The source dataset has about 200000 rows. There are separate data files for training and and testing.&nbsp;The full dataset column count is 42. For this experiment, I chose a subset of 14 columns. There are 5 continuous (numerical) variables, and 9 categorical ones in my training data. Selected columns:<br /><br />Age: <i>continuous</i><br />Workclass: <i>9 values</i><br />Education: <i>17 values</i><br />Marital status: <i>7 values</i><br />Major Occupation code: <i>15 values</i><br />Sex: <i>2 values</i><br />Race: <i>5 values</i><br />Capital gains: <i>continuous</i><br />Capital losses: <i>continuous</i><br />Country of birth: <i>43 values</i><br />Work weeks: <i>continuous</i><br />Wage per hour: <i>continuous</i><br />Household status summary: <i>8 values</i><br />Income category: <i>2 values (-50000 / 50000+ a year)</i><br /><br />There is no time series features in the data, so I've used the sample synthesis component from our <a href="https://boogiesoftware.com/datasynth/">Data Synthesizer Solution</a>.<br /><h3>Evaluation of the synthesis result</h3>Our sample synthesizer uses Wasserstein Generative Adversarial Network (WGAN) architecture. It can be used to generate synthetic data that retains statistical characteristics found in the training data, while the individual samples in training data cannot be identified from the synthetic counterpart.<br /><br />It is customary to have a neural network loss graphs available through TensorBoard. For the Boogie Software Data Synthesizer, we have built in-training visibility to the performance of the network with control plots that show how the synthesis works on selected details of the data. This is particularly helpful with GAN models, since there is no direct correspondence from an individual loss term to quality of the output.<br /><br /><div style="text-align: center;">Boogie Data Synthesizer Solution in-training Tensorboard Plots</div><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Zv8sUxCn3sk/XiVi1Rnc2YI/AAAAAAAAAKM/5C9IJckEUyYSEMMCyjzXSldI02Wl3Lq3wCLcBGAsYHQ/s1600/in_training_plots.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="400" data-original-width="800" src="https://1.bp.blogspot.com/-Zv8sUxCn3sk/XiVi1Rnc2YI/AAAAAAAAAKM/5C9IJckEUyYSEMMCyjzXSldI02Wl3Lq3wCLcBGAsYHQ/s1600/in_training_plots.png" /></a></div><div class="separator" style="clear: both; text-align: center;"></div><br />To reach these control plots, model was trained 15 minutes on a laptop without GPU (time is dependent on the data volume, the required data similarity level and available compute power). Our solution can be run in AWS SageMaker or Google Cloud AI platforms to maximise performance on large datasets.<br /><br />After training, I created a synthetic dataset of the similar volume with the training data (200000 samples). Then I ran a pairwise mutual information test, resulting in the following diagram.<br /><br /><div style="text-align: center;">Pairwise mutual information (real vs synthetic)<br /><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-dPPUrSXl7ls/Xh7zZLmwzJI/AAAAAAAAAJA/mIwH_a2I4fAQhGA-HgZjm_PB5tAqSuCBACLcBGAsYHQ/s1600/real_vs_synthetic_pairwise.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="590" data-original-width="1600" src="https://1.bp.blogspot.com/-dPPUrSXl7ls/Xh7zZLmwzJI/AAAAAAAAAJA/mIwH_a2I4fAQhGA-HgZjm_PB5tAqSuCBACLcBGAsYHQ/s1600/real_vs_synthetic_pairwise.png" /></a></div><br /></div>From this comparison we can see that in overview the cross-column correlations are retained in the generated synthetic data.<br /><h3>Synthetic data utility in machine learning</h3>Synthetic datasets can prove to be useful in various scenarios as listed above. But is it possible to do data science with synthetic datasets?<br /><br />This dataset is often used as an example for binary classification with imbalanced data, meaning that there are significantly different volumes of negative and positive cases. In this data, only a bit over 6% of the rows have income category of&nbsp;<i>50000+</i>. This makes it challenging for a classification algorithm to reach high accuracy on both classes. Therefore it is not a good idea to look at the accuracy of the prediction as a single value - a classifier that puts ALL the samples in the low income category will still reach overall accuracy of 94% due to the imbalance. To get a better understanding on model performance, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC curves</a> and <a href="https://en.wikipedia.org/wiki/Precision_and_recall">precision-recall curves</a> can help.<br /><br />For comparing the results, I trained a classifier for the real data and synthetic data separately. A small grid search was done to find the best hyperparameters which resulted in ROC AUC score of 0.98 and Precision-Recall score of 0.71 on the training data. Same hyperparameters were then used for training the classifier on both real and synthetic datasets. After training the LightGBM model, the classifier was evaluated against holdout data (real data that was never seen by either the synthesis or the classification algorithms).<br /><br />The following graphs show how the model trained with real data performs as compared to model trained with synthetic data created with <a href="https://boogiesoftware.com/datasynth/">Boogie Software Data Synthesizer</a> (<b>wgan</b>). To put the result in context, I trained three open source data synthesis implementations and then trained new classifiers on the synthetic datasets created with each of these. The compared synthesizers were <a href="https://github.com/sdv-dev/SDV">Synthetic Data Vault</a> (<b>sdv</b>) and <a href="https://github.com/sdv-dev/TGAN">Tabular GAN</a> (<b>tgan</b>) from Mit Data to AI Lab, and <a href="https://github.com/DataResponsibly/DataSynthesizer">DataSynthesizer</a> from DataResponsibly (<b>drds</b>).<br /><span style="font-size: x-small; line-height: 80%;">* Note that I have not used a lot of time to configure the comparison synthesizers, but used them with the default settings. It is likely that each synthesizers score could be different with a different set of parameters.</span><br /><br /><div style="text-align: center;">ROC Curves on holdout data for models trained with real and synthesized data</div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-5oVQpmzH340/Xh8FCK4_3lI/AAAAAAAAAJQ/eZJYigwL7JUsqm6YBZb41blY-hcYEtvjgCEwYBhgL/s1600/roc_curves.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="317" data-original-width="609" src="https://1.bp.blogspot.com/-5oVQpmzH340/Xh8FCK4_3lI/AAAAAAAAAJQ/eZJYigwL7JUsqm6YBZb41blY-hcYEtvjgCEwYBhgL/s1600/roc_curves.png" /></a></div><div class="separator" style="clear: both; text-align: center;"></div><div style="text-align: center;"><br /></div><div class="separator" style="clear: both; text-align: center;"></div>Not bad, the model trained with synthetic data performs reasonably well. When we look at the precision-recall curve though, the results is not as appealing.<br /><br /><div style="text-align: center;">Precision-Recall Curves on holdout data for models trained with real and synthesized data</div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-W7JlOoAPgPQ/Xh8RxncURbI/AAAAAAAAAJc/j9jjkbDDwjMPO_uUO9ZgHPkltt5iNikDACEwYBhgL/s1600/precision-recall-curve.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="317" data-original-width="609" src="https://1.bp.blogspot.com/-W7JlOoAPgPQ/Xh8RxncURbI/AAAAAAAAAJc/j9jjkbDDwjMPO_uUO9ZgHPkltt5iNikDACEwYBhgL/s1600/precision-recall-curve.png" /></a></div><div class="separator" style="clear: both; text-align: center;"></div><div style="text-align: center;"><br /></div><div class="separator" style="clear: both; text-align: center;"></div>All the models trained on synthetic data yield significantly lower precision-recall score than the model trained with real dataset. However, in a quick search for optimal classifier parameters on the synthetic data, I achieved a gain of 0.04-0.05 on the precision-recall score.<br /><h3>A peek at the model insight</h3>The column-specific comparison and pairwise mutual information analysis show that the synthetic dataset created with <a href="https://boogiesoftware.com/datasynth/">Boogie Software Data Synthesizer</a> is statistically similar to the real data. The classifier trained on synthetic data performs relatively well on the holdout real dataset particularly in the ROC and Precision-Recall curves. The final test I did was to compare how the trained model applies weight to different features in the data using <a href="https://github.com/slundberg/shap">SHAP</a>, a tool that can be used to visualise the inner workings of virtually any machine learning model.<br /><br />In this plot, you can see the average impact of each feature on the model output visualized on the holdout data. Class 0 is low income, Class 1 is high income. The key takeaways from this comparison:<br /><ul><li>Both models assign the most weight on the same features (age, workWeeks).</li><li>The distribution of impact magnitude is similar.&nbsp;</li><li>The model trained on synthetic data seems to be a slightly more biased on race and marital status as compared to the model trained on real data, but the difference is not huge.&nbsp;</li></ul><div style="text-align: center;">SHAP summary evaluation on models trained with real data (left) and synthetic data (right)</div><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-FQarsZTcmkM/XiAYvXToeDI/AAAAAAAAAJ0/fjWLPm4avyIJ9rXI23PiORljT9XqrcTpQCLcBGAsYHQ/s1600/shap_comparison.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="412" data-original-width="1219" src="https://1.bp.blogspot.com/-FQarsZTcmkM/XiAYvXToeDI/AAAAAAAAAJ0/fjWLPm4avyIJ9rXI23PiORljT9XqrcTpQCLcBGAsYHQ/s1600/shap_comparison.png" /></a></div><br /><h3><a href="https://www.blogger.com/u/1/null" name="Conclusions"></a>Conclusions</h3><div>Thank you for reading this far, I know there's quite a bit to digest at one go. When I started planning on this article, my intention was to get to know SHAP and LightGBM tools a bit more closely, and to see how realistic idea it is to develop a machine learning model with synthetic data only. My final verdict is summarised below. What do you think? I'll be happy to discuss the topic e.g. in <a href="https://www.linkedin.com/in/aleksi-sitomaniemi/">LinkedIn</a>.&nbsp;</div><blockquote text-align="left"><span style="font-size: medium; font-weight: bold; text-align: left;">1. There is no chance beating a model trained with real data...&nbsp;</span><br /><br /><span style="font-size: medium; font-weight: bold; text-align: left;">2. ...But when real data is not available, synthetic data <i>can</i> be used to develop and train machine learning models.</span><br /><br /><span style="font-size: medium; font-weight: bold; text-align: left;">3. Iterating on the model to reach better performance on synthetic data <i>will</i> result in better performance also when the model is applied in a real-world scenario.&nbsp;</span></blockquote><h3>Further reading</h3>At Boogie Software website and blog:<br /><ul><li><a href="https://boogiesoftware.com/ai/">Boogie Software AI Services</a></li><li><a href="https://boogiesoftware.com/datasynth/">Boogie Software Data Synthesizer Solution</a></li><li><a href="https://blog.boogiesoftware.com/2019/02/deep-learning-method-for-synthesis-of.html">Deep Learning Method For Synthesis of Tabular Data</a></li></ul>Elsewhere:<br /><ul><li><a href="http://www.myhealthmydata.eu/wp-content/uploads/2019/10/paper_142.pdf">On the Utility of Synthetic Data: An Empirical Evaluation on Machine Learning Tasks</a>&nbsp;(Hittmeir, Ekelhart &amp; Meyer 2019)</li></ul>